{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from lob_data_utils import lob, db_result, model, stocks_numbers\n",
    "from lob_data_utils.svm_calculation import lob_svm\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 24000\n",
    "stocks = stocks_numbers.chosen_stocks\n",
    "should_save_fig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stocks = {}\n",
    "d_cv_stocks = {}\n",
    "d_test_stocks = {}\n",
    "for s in stocks:\n",
    "    d,  d_test = lob.load_prepared_data(s, length=data_length)\n",
    "    d.index = pd.to_datetime(d['Unnamed: 0'].values)\n",
    "    d_test.index = pd.to_datetime(d_test['Unnamed: 0'].values)\n",
    "    d['prev_queue_imbalance'] = [None] + d['queue_imbalance'].iloc[0:len(d)-1].values.tolist()\n",
    "    d.dropna(inplace=True)\n",
    "    d_test['prev_queue_imbalance'] = [None] + d_test['queue_imbalance'].iloc[0:len(d_test)-1].values.tolist()\n",
    "    d_test.dropna(inplace=True)\n",
    "    d_stocks[s] = d\n",
    "    d_test_stocks[s] = d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>sum_sell_ask</th>\n",
       "      <th>sum_buy_bid</th>\n",
       "      <th>mid_price_indicator</th>\n",
       "      <th>queue_imbalance</th>\n",
       "      <th>prev_queue_imbalance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:31:00</th>\n",
       "      <td>2013-09-02 08:31:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 19522.0), (750.0, 51865.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>19522.0</td>\n",
       "      <td>8078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.414638</td>\n",
       "      <td>-0.573878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:32:00</th>\n",
       "      <td>2013-09-02 08:32:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 13371.0), (750.0, 51046.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>13371.0</td>\n",
       "      <td>16818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114181</td>\n",
       "      <td>-0.414638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:33:00</th>\n",
       "      <td>2013-09-02 08:33:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 20645.0), (750.0, 51474.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>20645.0</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.482532</td>\n",
       "      <td>0.114181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:34:00</th>\n",
       "      <td>2013-09-02 08:34:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.5, 14676.0), (750.0, 51474.0), (750.5, 1...</td>\n",
       "      <td>748.5</td>\n",
       "      <td>749.5</td>\n",
       "      <td>749.0</td>\n",
       "      <td>14676.0</td>\n",
       "      <td>7206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.341376</td>\n",
       "      <td>-0.482532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-02 08:35:00</th>\n",
       "      <td>2013-09-02 08:35:00</td>\n",
       "      <td>[(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...</td>\n",
       "      <td>[(749.0, 9652.0), (749.5, 35846.0), (750.0, 42...</td>\n",
       "      <td>748.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>748.5</td>\n",
       "      <td>9652.0</td>\n",
       "      <td>5395.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.282914</td>\n",
       "      <td>-0.341376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Unnamed: 0  \\\n",
       "2013-09-02 08:31:00  2013-09-02 08:31:00   \n",
       "2013-09-02 08:32:00  2013-09-02 08:32:00   \n",
       "2013-09-02 08:33:00  2013-09-02 08:33:00   \n",
       "2013-09-02 08:34:00  2013-09-02 08:34:00   \n",
       "2013-09-02 08:35:00  2013-09-02 08:35:00   \n",
       "\n",
       "                                                                   bid  \\\n",
       "2013-09-02 08:31:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:32:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:33:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:34:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "2013-09-02 08:35:00  [(550.0, 4600.0), (590.0, 3500.0), (666.0, 956...   \n",
       "\n",
       "                                                                   ask  \\\n",
       "2013-09-02 08:31:00  [(749.5, 19522.0), (750.0, 51865.0), (750.5, 1...   \n",
       "2013-09-02 08:32:00  [(749.5, 13371.0), (750.0, 51046.0), (750.5, 1...   \n",
       "2013-09-02 08:33:00  [(749.5, 20645.0), (750.0, 51474.0), (750.5, 1...   \n",
       "2013-09-02 08:34:00  [(749.5, 14676.0), (750.0, 51474.0), (750.5, 1...   \n",
       "2013-09-02 08:35:00  [(749.0, 9652.0), (749.5, 35846.0), (750.0, 42...   \n",
       "\n",
       "                     bid_price  ask_price  mid_price  sum_sell_ask  \\\n",
       "2013-09-02 08:31:00      748.5      749.5      749.0       19522.0   \n",
       "2013-09-02 08:32:00      748.5      749.5      749.0       13371.0   \n",
       "2013-09-02 08:33:00      748.5      749.5      749.0       20645.0   \n",
       "2013-09-02 08:34:00      748.5      749.5      749.0       14676.0   \n",
       "2013-09-02 08:35:00      748.0      749.0      748.5        9652.0   \n",
       "\n",
       "                     sum_buy_bid  mid_price_indicator  queue_imbalance  \\\n",
       "2013-09-02 08:31:00       8078.0                  0.0        -0.414638   \n",
       "2013-09-02 08:32:00      16818.0                  0.0         0.114181   \n",
       "2013-09-02 08:33:00       7206.0                  0.0        -0.482532   \n",
       "2013-09-02 08:34:00       7206.0                  0.0        -0.341376   \n",
       "2013-09-02 08:35:00       5395.0                  1.0        -0.282914   \n",
       "\n",
       "                     prev_queue_imbalance  \n",
       "2013-09-02 08:31:00             -0.573878  \n",
       "2013-09-02 08:32:00             -0.414638  \n",
       "2013-09-02 08:33:00              0.114181  \n",
       "2013-09-02 08:34:00             -0.482532  \n",
       "2013-09-02 08:35:00             -0.341376  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_stocks['3459'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with queue imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = {}\n",
    "for s in stocks:\n",
    "    df_res_temp = pd.read_csv(\n",
    "        '../svm_queue_imbalance/res_svm/svm_sigmoid_{}_len{}.csv'.format(s, data_length))\n",
    "    df_res[s] = df_res_temp\n",
    "    df_res[s].index = list(range(len(df_res[s])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>coef0</th>\n",
       "      <th>f1</th>\n",
       "      <th>features</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kappa</th>\n",
       "      <th>kernel</th>\n",
       "      <th>matthews</th>\n",
       "      <th>precision</th>\n",
       "      <th>...</th>\n",
       "      <th>train_matthews</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_val_f1</th>\n",
       "      <th>train_val_kappa</th>\n",
       "      <th>train_val_matthews</th>\n",
       "      <th>train_val_precision</th>\n",
       "      <th>train_val_recall</th>\n",
       "      <th>train_val_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.497593</td>\n",
       "      <td>que</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.099606</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.491552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084010</td>\n",
       "      <td>0.473642</td>\n",
       "      <td>0.563770</td>\n",
       "      <td>0.542363</td>\n",
       "      <td>0.487147</td>\n",
       "      <td>0.077044</td>\n",
       "      <td>0.077467</td>\n",
       "      <td>0.472729</td>\n",
       "      <td>0.504807</td>\n",
       "      <td>0.538808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>10.000</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.346803</td>\n",
       "      <td>que</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.123657</td>\n",
       "      <td>0.235997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130553</td>\n",
       "      <td>0.247441</td>\n",
       "      <td>0.635929</td>\n",
       "      <td>0.582217</td>\n",
       "      <td>0.363559</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.254739</td>\n",
       "      <td>0.634881</td>\n",
       "      <td>0.584637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.444472</td>\n",
       "      <td>que</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.111446</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.345721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023102</td>\n",
       "      <td>0.282660</td>\n",
       "      <td>0.554722</td>\n",
       "      <td>0.487429</td>\n",
       "      <td>0.437130</td>\n",
       "      <td>0.105751</td>\n",
       "      <td>0.119926</td>\n",
       "      <td>0.343775</td>\n",
       "      <td>0.611828</td>\n",
       "      <td>0.564972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10.000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.425296</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.140375</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.145372</td>\n",
       "      <td>0.365136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.367224</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.568335</td>\n",
       "      <td>0.418693</td>\n",
       "      <td>0.119653</td>\n",
       "      <td>0.125082</td>\n",
       "      <td>0.352671</td>\n",
       "      <td>0.517453</td>\n",
       "      <td>0.567918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>100.000</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.293089</td>\n",
       "      <td>que</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.146541</td>\n",
       "      <td>0.189271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>0.192221</td>\n",
       "      <td>0.714385</td>\n",
       "      <td>0.594016</td>\n",
       "      <td>0.319473</td>\n",
       "      <td>0.111632</td>\n",
       "      <td>0.151331</td>\n",
       "      <td>0.210574</td>\n",
       "      <td>0.662441</td>\n",
       "      <td>0.604843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.519890</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.062361</td>\n",
       "      <td>0.479484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063964</td>\n",
       "      <td>0.477580</td>\n",
       "      <td>0.597335</td>\n",
       "      <td>0.531897</td>\n",
       "      <td>0.524661</td>\n",
       "      <td>0.063846</td>\n",
       "      <td>0.065219</td>\n",
       "      <td>0.477838</td>\n",
       "      <td>0.582866</td>\n",
       "      <td>0.532586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.425378</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.109039</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.332377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118834</td>\n",
       "      <td>0.324307</td>\n",
       "      <td>0.572923</td>\n",
       "      <td>0.566919</td>\n",
       "      <td>0.409281</td>\n",
       "      <td>0.108513</td>\n",
       "      <td>0.118624</td>\n",
       "      <td>0.323408</td>\n",
       "      <td>0.558131</td>\n",
       "      <td>0.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.010</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.420016</td>\n",
       "      <td>que</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.138216</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.146256</td>\n",
       "      <td>0.345570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.604538</td>\n",
       "      <td>0.570263</td>\n",
       "      <td>0.417605</td>\n",
       "      <td>0.108017</td>\n",
       "      <td>0.116642</td>\n",
       "      <td>0.340162</td>\n",
       "      <td>0.549144</td>\n",
       "      <td>0.563929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.100</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.261750</td>\n",
       "      <td>que</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.091470</td>\n",
       "      <td>0.208937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.151473</td>\n",
       "      <td>0.514503</td>\n",
       "      <td>0.515508</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>0.037614</td>\n",
       "      <td>0.048580</td>\n",
       "      <td>0.152842</td>\n",
       "      <td>0.455017</td>\n",
       "      <td>0.534461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10.000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.455860</td>\n",
       "      <td>que</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.123911</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.135066</td>\n",
       "      <td>0.366351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147290</td>\n",
       "      <td>0.385433</td>\n",
       "      <td>0.564751</td>\n",
       "      <td>0.579239</td>\n",
       "      <td>0.464308</td>\n",
       "      <td>0.153763</td>\n",
       "      <td>0.162579</td>\n",
       "      <td>0.385886</td>\n",
       "      <td>0.583737</td>\n",
       "      <td>0.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.496518</td>\n",
       "      <td>que</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.410968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>0.347686</td>\n",
       "      <td>0.561292</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>0.494748</td>\n",
       "      <td>0.090748</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>0.404025</td>\n",
       "      <td>0.641871</td>\n",
       "      <td>0.551053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>100.000</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.419942</td>\n",
       "      <td>que</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.129108</td>\n",
       "      <td>0.316442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110880</td>\n",
       "      <td>0.323346</td>\n",
       "      <td>0.582380</td>\n",
       "      <td>0.562204</td>\n",
       "      <td>0.418853</td>\n",
       "      <td>0.097557</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.324313</td>\n",
       "      <td>0.591723</td>\n",
       "      <td>0.561375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.010</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.441328</td>\n",
       "      <td>que</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.119692</td>\n",
       "      <td>0.350044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124912</td>\n",
       "      <td>0.364625</td>\n",
       "      <td>0.587245</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.120633</td>\n",
       "      <td>0.357658</td>\n",
       "      <td>0.613283</td>\n",
       "      <td>0.564826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.001</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.415425</td>\n",
       "      <td>que</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.121182</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>0.308560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129047</td>\n",
       "      <td>0.304940</td>\n",
       "      <td>0.642238</td>\n",
       "      <td>0.574132</td>\n",
       "      <td>0.407315</td>\n",
       "      <td>0.102108</td>\n",
       "      <td>0.124448</td>\n",
       "      <td>0.295800</td>\n",
       "      <td>0.654387</td>\n",
       "      <td>0.571875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10.000</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.491008</td>\n",
       "      <td>que</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.076422</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.078425</td>\n",
       "      <td>0.437605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.437583</td>\n",
       "      <td>0.557695</td>\n",
       "      <td>0.539532</td>\n",
       "      <td>0.493537</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>0.085181</td>\n",
       "      <td>0.440641</td>\n",
       "      <td>0.560889</td>\n",
       "      <td>0.543465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            C  Unnamed: 0   coef0        f1 features     gamma     kappa  \\\n",
       "25      0.001        25.0   0.010  0.497593      que    10.000  0.099606   \n",
       "177    10.000       177.0   1.000  0.346803      que     0.010  0.093323   \n",
       "34      0.001        34.0  10.000  0.444472      que   100.000  0.111446   \n",
       "180    10.000       180.0   0.001  0.425296      que     0.100  0.140375   \n",
       "219   100.000       219.0   1.000  0.293089      que     0.010  0.105413   \n",
       "141     1.000       141.0   1.000  0.519890      que     0.100  0.061360   \n",
       "254  1000.000       254.0   0.100  0.425378      que     0.001  0.109039   \n",
       "63      0.010        63.0   1.000  0.420016      que     1.000  0.138216   \n",
       "102     0.100       102.0   0.001  0.261750      que     1.000  0.078826   \n",
       "180    10.000       180.0   0.001  0.455860      que     0.100  0.123911   \n",
       "34      0.001        34.0  10.000  0.496518      que   100.000  0.103416   \n",
       "218   100.000       218.0   0.100  0.419942      que     0.010  0.111573   \n",
       "57      0.010        57.0   1.000  0.441328      que     1.000  0.106374   \n",
       "40      0.001        40.0  10.000  0.415425      que  1000.000  0.121182   \n",
       "171    10.000       171.0   1.000  0.491008      que     0.001  0.076422   \n",
       "\n",
       "      kernel  matthews  precision        ...          train_matthews  \\\n",
       "25   sigmoid  0.101253   0.491552        ...                0.084010   \n",
       "177  sigmoid  0.123657   0.235997        ...                0.130553   \n",
       "34   sigmoid  0.126050   0.345721        ...               -0.023102   \n",
       "180  sigmoid  0.145372   0.365136        ...                0.127401   \n",
       "219  sigmoid  0.146541   0.189271        ...                0.134776   \n",
       "141  sigmoid  0.062361   0.479484        ...                0.063964   \n",
       "254  sigmoid  0.122881   0.332377        ...                0.118834   \n",
       "63   sigmoid  0.146256   0.345570        ...                0.125885   \n",
       "102  sigmoid  0.091470   0.208937        ...                0.021764   \n",
       "180  sigmoid  0.135066   0.366351        ...                0.147290   \n",
       "34   sigmoid  0.113281   0.410968        ...               -0.033182   \n",
       "218  sigmoid  0.129108   0.316442        ...                0.110880   \n",
       "57   sigmoid  0.119692   0.350044        ...                0.124912   \n",
       "40   sigmoid  0.142101   0.308560        ...                0.129047   \n",
       "171  sigmoid  0.078425   0.437605        ...                0.077495   \n",
       "\n",
       "     train_precision  train_recall  train_roc_auc  train_val_f1  \\\n",
       "25          0.473642      0.563770       0.542363      0.487147   \n",
       "177         0.247441      0.635929       0.582217      0.363559   \n",
       "34          0.282660      0.554722       0.487429      0.437130   \n",
       "180         0.367224      0.494805       0.568335      0.418693   \n",
       "219         0.192221      0.714385       0.594016      0.319473   \n",
       "141         0.477580      0.597335       0.531897      0.524661   \n",
       "254         0.324307      0.572923       0.566919      0.409281   \n",
       "63          0.333817      0.604538       0.570263      0.417605   \n",
       "102         0.151473      0.514503       0.515508      0.218879   \n",
       "180         0.385433      0.564751       0.579239      0.464308   \n",
       "34          0.347686      0.561292       0.482970      0.494748   \n",
       "218         0.323346      0.582380       0.562204      0.418853   \n",
       "57          0.364625      0.587245       0.567742      0.448866   \n",
       "40          0.304940      0.642238       0.574132      0.407315   \n",
       "171         0.437583      0.557695       0.539532      0.493537   \n",
       "\n",
       "     train_val_kappa  train_val_matthews  train_val_precision  \\\n",
       "25          0.077044            0.077467             0.472729   \n",
       "177         0.108610            0.135556             0.254739   \n",
       "34          0.105751            0.119926             0.343775   \n",
       "180         0.119653            0.125082             0.352671   \n",
       "219         0.111632            0.151331             0.210574   \n",
       "141         0.063846            0.065219             0.477838   \n",
       "254         0.108513            0.118624             0.323408   \n",
       "63          0.108017            0.116642             0.340162   \n",
       "102         0.037614            0.048580             0.152842   \n",
       "180         0.153763            0.162579             0.385886   \n",
       "34          0.090748            0.100003             0.404025   \n",
       "218         0.097557            0.109590             0.324313   \n",
       "57          0.108135            0.120633             0.357658   \n",
       "40          0.102108            0.124448             0.295800   \n",
       "171         0.083141            0.085181             0.440641   \n",
       "\n",
       "     train_val_recall  train_val_roc_auc  \n",
       "25           0.504807           0.538808  \n",
       "177          0.634881           0.584637  \n",
       "34           0.611828           0.564972  \n",
       "180          0.517453           0.567918  \n",
       "219          0.662441           0.604843  \n",
       "141          0.582866           0.532586  \n",
       "254          0.558131           0.566700  \n",
       "63           0.549144           0.563929  \n",
       "102          0.455017           0.534461  \n",
       "180          0.583737           0.587800  \n",
       "34           0.641871           0.551053  \n",
       "218          0.591723           0.561375  \n",
       "57           0.613283           0.564826  \n",
       "40           0.654387           0.571875  \n",
       "171          0.560889           0.543465  \n",
       "\n",
       "[15 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_svm = pd.DataFrame()\n",
    "for s in stocks:\n",
    "    idx_max = df_res[s]['matthews'].idxmax()\n",
    "    df_best_svm = df_best_svm.append(df_res[s].loc[idx_max])\n",
    "df_best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrlrrr}\n",
      "\\toprule\n",
      "{} &    stock &   kernel &         C &     gamma &   coef0 \\\\\n",
      "\\midrule\n",
      "25  &   9061.0 &  sigmoid &     0.001 &    10.000 &   0.010 \\\\\n",
      "177 &   3459.0 &  sigmoid &    10.000 &     0.010 &   1.000 \\\\\n",
      "34  &   4549.0 &  sigmoid &     0.001 &   100.000 &  10.000 \\\\\n",
      "180 &   9761.0 &  sigmoid &    10.000 &     0.100 &   0.001 \\\\\n",
      "219 &   4851.0 &  sigmoid &   100.000 &     0.010 &   1.000 \\\\\n",
      "141 &   9062.0 &  sigmoid &     1.000 &     0.100 &   1.000 \\\\\n",
      "254 &  11869.0 &  sigmoid &  1000.000 &     0.001 &   0.100 \\\\\n",
      "63  &  12255.0 &  sigmoid &     0.010 &     1.000 &   1.000 \\\\\n",
      "102 &   2748.0 &  sigmoid &     0.100 &     1.000 &   0.001 \\\\\n",
      "180 &   4320.0 &  sigmoid &    10.000 &     0.100 &   0.001 \\\\\n",
      "34  &  11583.0 &  sigmoid &     0.001 &   100.000 &  10.000 \\\\\n",
      "218 &   4799.0 &  sigmoid &   100.000 &     0.010 &   0.100 \\\\\n",
      "57  &   9268.0 &  sigmoid &     0.010 &     1.000 &   1.000 \\\\\n",
      "40  &  10470.0 &  sigmoid &     0.001 &  1000.000 &  10.000 \\\\\n",
      "171 &   9058.0 &  sigmoid &    10.000 &     0.001 &   1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_best_svm[['stock', 'kernel', 'C', 'gamma', 'coef0']].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn import utils\n",
    "\n",
    "def get_classes_weights(y_train):\n",
    "    classes = np.unique(y_train)\n",
    "    class_weight_list = utils.class_weight.compute_class_weight('balanced', classes, y_train)\n",
    "    class_weights = {classes[0]: class_weight_list[0], classes[1]: class_weight_list[1]}\n",
    "    return class_weights\n",
    "\n",
    "def fit_best_svm_classifier(df_best_svm, df, stock=None):\n",
    "    stock = int(stock)\n",
    "    gamma = df_best_svm[df_best_svm['stock'] == stock]['gamma'].values[0]\n",
    "    coef0 = df_best_svm[df_best_svm['stock'] == stock]['coef0'].values[0]\n",
    "    c = df_best_svm[df_best_svm['stock'] == stock]['C'].values[0]\n",
    "    kernel = df_best_svm[df_best_svm['stock'] == stock]['kernel'].values[0]\n",
    "\n",
    "    X = df['queue_imbalance'].values.reshape(-1, 1)\n",
    "    y = df['mid_price_indicator']\n",
    "   \n",
    "    weights = get_classes_weights(y)\n",
    "    clf = SVC(gamma=gamma, C=c, coef0=coef0, kernel=kernel, random_state=23131, class_weight=weights)\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_dict_for_data(functions_to_run, dfs, log_clf, stock):\n",
    "    scores = {'stock': stock}\n",
    "    for func_name, func in functions_to_run.items():\n",
    "        for df_name, df in dfs.items():\n",
    "            pred = log_clf.predict(df['queue_imbalance'].values.reshape(-1, 1))\n",
    "            df['pred'] = pred\n",
    "            scores['{}_{}'.format(df_name, func_name)] = func(df['mid_price_indicator'], pred)\n",
    "    return scores\n",
    "            \n",
    "functions_to_run = {'precision': metrics.precision_score, 'roc_auc': metrics.roc_auc_score,\n",
    "                   'f1_score': metrics.f1_score, 'recall': metrics.recall_score, \n",
    "                   'matthews': metrics.matthews_corrcoef, 'kappa': metrics.cohen_kappa_score}\n",
    "scores = []\n",
    "for stock in stocks:\n",
    "    log_clf = fit_best_svm_classifier(df_best_svm, d_stocks[stock], stock=stock)\n",
    "    dfs = {'train': d_stocks[stock], 'test': d_test_stocks[stock], }\n",
    "    res_validation = model.validate_model(\n",
    "        fit_best_svm_classifier(df_best_svm, d_stocks[stock], stock=stock), \n",
    "        d_stocks[stock][['queue_imbalance']], d_stocks[stock]['mid_price_indicator'])\n",
    "    res = get_scores_dict_for_data(functions_to_run, dfs, log_clf, stock)\n",
    "    res = {**res, **res_validation}\n",
    "    scores.append(res)\n",
    "df_scores = pd.DataFrame(scores, index=stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>kappa</th>\n",
       "      <th>matthews</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>stock</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_kappa</th>\n",
       "      <th>test_matthews</th>\n",
       "      <th>...</th>\n",
       "      <th>train_matthews</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>train_val_f1</th>\n",
       "      <th>train_val_kappa</th>\n",
       "      <th>train_val_matthews</th>\n",
       "      <th>train_val_precision</th>\n",
       "      <th>train_val_recall</th>\n",
       "      <th>train_val_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>0.497593</td>\n",
       "      <td>0.099606</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.491552</td>\n",
       "      <td>0.513918</td>\n",
       "      <td>0.550135</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.514865</td>\n",
       "      <td>0.087674</td>\n",
       "      <td>0.089317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084010</td>\n",
       "      <td>0.473642</td>\n",
       "      <td>0.563770</td>\n",
       "      <td>0.542363</td>\n",
       "      <td>[0.48513827862496767, 0.46519202062695075, 0.4...</td>\n",
       "      <td>[0.07541622814166549, 0.07436635023761451, 0.0...</td>\n",
       "      <td>[0.07549759566248633, 0.0743840975752264, 0.08...</td>\n",
       "      <td>[0.47291509196271103, 0.47113798790544253, 0.4...</td>\n",
       "      <td>[0.49801008224993365, 0.45939426427231306, 0.4...</td>\n",
       "      <td>[0.5379477368473236, 0.5370659747472899, 0.542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.346803</td>\n",
       "      <td>0.093323</td>\n",
       "      <td>0.123657</td>\n",
       "      <td>0.235997</td>\n",
       "      <td>0.659755</td>\n",
       "      <td>0.578305</td>\n",
       "      <td>3459</td>\n",
       "      <td>0.355052</td>\n",
       "      <td>0.108968</td>\n",
       "      <td>0.131771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130553</td>\n",
       "      <td>0.247441</td>\n",
       "      <td>0.635929</td>\n",
       "      <td>0.582217</td>\n",
       "      <td>[0.36643219368558805, 0.37091264031234755, 0.3...</td>\n",
       "      <td>[0.11068791437404635, 0.11388203740888381, 0.1...</td>\n",
       "      <td>[0.1375948325984511, 0.14128969867782512, 0.13...</td>\n",
       "      <td>[0.2574712643678161, 0.2611683848797251, 0.253...</td>\n",
       "      <td>[0.6352807714123653, 0.6397306397306397, 0.618...</td>\n",
       "      <td>[0.5856668148931979, 0.5876170122173291, 0.586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>0.444472</td>\n",
       "      <td>0.111446</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.345721</td>\n",
       "      <td>0.628882</td>\n",
       "      <td>0.568979</td>\n",
       "      <td>4549</td>\n",
       "      <td>0.369752</td>\n",
       "      <td>-0.010462</td>\n",
       "      <td>-0.012427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023102</td>\n",
       "      <td>0.282660</td>\n",
       "      <td>0.554722</td>\n",
       "      <td>0.487429</td>\n",
       "      <td>[0.4154952598888526, 0.41458299725762215, 0.44...</td>\n",
       "      <td>[0.1133391131902024, 0.10787921816098733, 0.10...</td>\n",
       "      <td>[0.11717896366058196, 0.1121591275914303, 0.12...</td>\n",
       "      <td>[0.35592271072528703, 0.3514770240700219, 0.33...</td>\n",
       "      <td>[0.49901845308205733, 0.5053086905230043, 0.66...</td>\n",
       "      <td>[0.5633648432454638, 0.5608879266267561, 0.570...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.425296</td>\n",
       "      <td>0.140375</td>\n",
       "      <td>0.145372</td>\n",
       "      <td>0.365136</td>\n",
       "      <td>0.511876</td>\n",
       "      <td>0.579031</td>\n",
       "      <td>9761</td>\n",
       "      <td>0.418251</td>\n",
       "      <td>0.107302</td>\n",
       "      <td>0.110216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127401</td>\n",
       "      <td>0.367224</td>\n",
       "      <td>0.494805</td>\n",
       "      <td>0.568335</td>\n",
       "      <td>[0.4483916083916084, 0.4189549662639259, 0.407...</td>\n",
       "      <td>[0.10629670812162728, 0.1058349086570548, 0.11...</td>\n",
       "      <td>[0.11686657327253876, 0.11140406459736009, 0.1...</td>\n",
       "      <td>[0.3568566340160285, 0.34829115575267416, 0.34...</td>\n",
       "      <td>[0.6030850263355907, 0.5255905511811023, 0.492...</td>\n",
       "      <td>[0.5634511995037109, 0.5608550977409149, 0.565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>0.293089</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.146541</td>\n",
       "      <td>0.189271</td>\n",
       "      <td>0.654920</td>\n",
       "      <td>0.606391</td>\n",
       "      <td>4851</td>\n",
       "      <td>0.281892</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.131945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>0.192221</td>\n",
       "      <td>0.714385</td>\n",
       "      <td>0.594016</td>\n",
       "      <td>[0.31987991994663106, 0.3283737024221453, 0.32...</td>\n",
       "      <td>[0.09450526395297976, 0.10938668717232536, 0.1...</td>\n",
       "      <td>[0.13215161824598573, 0.14791349497697015, 0.1...</td>\n",
       "      <td>[0.20975503062117234, 0.21781042001377093, 0.2...</td>\n",
       "      <td>[0.6734550561797753, 0.6669009135628953, 0.657...</td>\n",
       "      <td>[0.5892956694403876, 0.6000897336918831, 0.608...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>0.519890</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>0.062361</td>\n",
       "      <td>0.479484</td>\n",
       "      <td>0.568150</td>\n",
       "      <td>0.531206</td>\n",
       "      <td>9062</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.052097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063964</td>\n",
       "      <td>0.477580</td>\n",
       "      <td>0.597335</td>\n",
       "      <td>0.531897</td>\n",
       "      <td>[0.5312393308296347, 0.5292244712303844, 0.528...</td>\n",
       "      <td>[0.06732105946098077, 0.06276835314999507, 0.0...</td>\n",
       "      <td>[0.06900973402586912, 0.06437256470834406, 0.0...</td>\n",
       "      <td>[0.47837671654027464, 0.47616124411704525, 0.4...</td>\n",
       "      <td>[0.5972364380757421, 0.5955976452521116, 0.597...</td>\n",
       "      <td>[0.5344496493887118, 0.5321284199693517, 0.532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.425378</td>\n",
       "      <td>0.109039</td>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.332377</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.567714</td>\n",
       "      <td>11869</td>\n",
       "      <td>0.412271</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.104974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118834</td>\n",
       "      <td>0.324307</td>\n",
       "      <td>0.572923</td>\n",
       "      <td>0.566919</td>\n",
       "      <td>[0.39735772357723576, 0.3945140535049103, 0.40...</td>\n",
       "      <td>[0.1144433911912599, 0.11096215581148583, 0.10...</td>\n",
       "      <td>[0.12202325950135805, 0.11857469519514513, 0.1...</td>\n",
       "      <td>[0.3214579336804604, 0.3181321682140907, 0.320...</td>\n",
       "      <td>[0.5201773835920177, 0.5191622103386809, 0.557...</td>\n",
       "      <td>[0.5687440240989454, 0.5669410804817923, 0.566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>0.420016</td>\n",
       "      <td>0.138216</td>\n",
       "      <td>0.146256</td>\n",
       "      <td>0.345570</td>\n",
       "      <td>0.537134</td>\n",
       "      <td>0.581062</td>\n",
       "      <td>12255</td>\n",
       "      <td>0.415247</td>\n",
       "      <td>0.096768</td>\n",
       "      <td>0.108394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.333817</td>\n",
       "      <td>0.604538</td>\n",
       "      <td>0.570263</td>\n",
       "      <td>[0.427263479145473, 0.42742276766821835, 0.428...</td>\n",
       "      <td>[0.0961386723705897, 0.09462290018094621, 0.11...</td>\n",
       "      <td>[0.10595648786121947, 0.10839509666510291, 0.1...</td>\n",
       "      <td>[0.33738811108560934, 0.32664941785252266, 0.3...</td>\n",
       "      <td>[0.5824088748019017, 0.6181150550795593, 0.608...</td>\n",
       "      <td>[0.5584194027291238, 0.5601732431916764, 0.571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.261750</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>0.091470</td>\n",
       "      <td>0.208937</td>\n",
       "      <td>0.454939</td>\n",
       "      <td>0.554845</td>\n",
       "      <td>2748</td>\n",
       "      <td>0.216625</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.008427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.151473</td>\n",
       "      <td>0.514503</td>\n",
       "      <td>0.515508</td>\n",
       "      <td>[0.1970746728252502, 0.20774487471526198, 0.19...</td>\n",
       "      <td>[0.056794689296525425, 0.05508665549958858, 0....</td>\n",
       "      <td>[0.056835699352604664, 0.07861471243916973, 0....</td>\n",
       "      <td>[0.19090231170768082, 0.12998859749144812, 0.1...</td>\n",
       "      <td>[0.20365950676213207, 0.5170068027210885, 0.47...</td>\n",
       "      <td>[0.5291864753949922, 0.5639349964134577, 0.532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.455860</td>\n",
       "      <td>0.123911</td>\n",
       "      <td>0.135066</td>\n",
       "      <td>0.366351</td>\n",
       "      <td>0.604171</td>\n",
       "      <td>0.573556</td>\n",
       "      <td>4320</td>\n",
       "      <td>0.444010</td>\n",
       "      <td>0.129812</td>\n",
       "      <td>0.135263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147290</td>\n",
       "      <td>0.385433</td>\n",
       "      <td>0.564751</td>\n",
       "      <td>0.579239</td>\n",
       "      <td>[0.48148148148148157, 0.4751958224543081, 0.45...</td>\n",
       "      <td>[0.1339327014120122, 0.1580016126696191, 0.163...</td>\n",
       "      <td>[0.14685468697513263, 0.16839180339384435, 0.1...</td>\n",
       "      <td>[0.3865546218487395, 0.3909307875894988, 0.384...</td>\n",
       "      <td>[0.6382070437566703, 0.6057692307692307, 0.549...</td>\n",
       "      <td>[0.5784034880602763, 0.5909596859708968, 0.591...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.496518</td>\n",
       "      <td>0.103416</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.410968</td>\n",
       "      <td>0.633230</td>\n",
       "      <td>0.557927</td>\n",
       "      <td>11583</td>\n",
       "      <td>0.435613</td>\n",
       "      <td>-0.021474</td>\n",
       "      <td>-0.024324</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>0.347686</td>\n",
       "      <td>0.561292</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>[0.4632989115266536, 0.5016509433962264, 0.502...</td>\n",
       "      <td>[0.09957174022126758, 0.08704232152473856, 0.0...</td>\n",
       "      <td>[0.10194356282982467, 0.09854128216431536, 0.0...</td>\n",
       "      <td>[0.41078940856223706, 0.39943661971830985, 0.4...</td>\n",
       "      <td>[0.5312, 0.6741679873217116, 0.67233238904627,...</td>\n",
       "      <td>[0.5530107142857144, 0.5500103850432616, 0.548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.419942</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>0.129108</td>\n",
       "      <td>0.316442</td>\n",
       "      <td>0.626217</td>\n",
       "      <td>0.573225</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.410857</td>\n",
       "      <td>0.110791</td>\n",
       "      <td>0.121606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110880</td>\n",
       "      <td>0.323346</td>\n",
       "      <td>0.582380</td>\n",
       "      <td>0.562204</td>\n",
       "      <td>[0.41729761211415256, 0.416260162601626, 0.421...</td>\n",
       "      <td>[0.08250192354959152, 0.09017513171986236, 0.1...</td>\n",
       "      <td>[0.09114513573979705, 0.09979146929501058, 0.1...</td>\n",
       "      <td>[0.3285943590919514, 0.32653061224489793, 0.32...</td>\n",
       "      <td>[0.5715995213402473, 0.5739910313901345, 0.600...</td>\n",
       "      <td>[0.5503542798081101, 0.5554904136542509, 0.563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.441328</td>\n",
       "      <td>0.106374</td>\n",
       "      <td>0.119692</td>\n",
       "      <td>0.350044</td>\n",
       "      <td>0.609453</td>\n",
       "      <td>0.564564</td>\n",
       "      <td>9268</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>0.120074</td>\n",
       "      <td>0.131940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124912</td>\n",
       "      <td>0.364625</td>\n",
       "      <td>0.587245</td>\n",
       "      <td>0.567742</td>\n",
       "      <td>[0.43129032258064515, 0.45442838746601805, 0.4...</td>\n",
       "      <td>[0.1239176031724506, 0.12317860195160124, 0.10...</td>\n",
       "      <td>[0.12580197480673536, 0.13333909594845167, 0.1...</td>\n",
       "      <td>[0.38787351319988395, 0.3669979200369771, 0.34...</td>\n",
       "      <td>[0.48565201598256447, 0.5965439519158527, 0.67...</td>\n",
       "      <td>[0.5661682718894738, 0.5723936978777681, 0.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.415425</td>\n",
       "      <td>0.121182</td>\n",
       "      <td>0.142101</td>\n",
       "      <td>0.308560</td>\n",
       "      <td>0.638472</td>\n",
       "      <td>0.581989</td>\n",
       "      <td>10470</td>\n",
       "      <td>0.420223</td>\n",
       "      <td>0.111498</td>\n",
       "      <td>0.126214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129047</td>\n",
       "      <td>0.304940</td>\n",
       "      <td>0.642238</td>\n",
       "      <td>0.574132</td>\n",
       "      <td>[0.4161394629551526, 0.40166882462954967, 0.39...</td>\n",
       "      <td>[0.09754143976995044, 0.09133215776089021, 0.0...</td>\n",
       "      <td>[0.11828182298290651, 0.11149021907733327, 0.1...</td>\n",
       "      <td>[0.3046521202140799, 0.29156223893065997, 0.28...</td>\n",
       "      <td>[0.656319290465632, 0.6453999075358299, 0.6702...</td>\n",
       "      <td>[0.5671086405960308, 0.5642421665079332, 0.573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.491008</td>\n",
       "      <td>0.076422</td>\n",
       "      <td>0.078425</td>\n",
       "      <td>0.437605</td>\n",
       "      <td>0.559800</td>\n",
       "      <td>0.540008</td>\n",
       "      <td>9058</td>\n",
       "      <td>0.497115</td>\n",
       "      <td>0.092606</td>\n",
       "      <td>0.094555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.437583</td>\n",
       "      <td>0.557695</td>\n",
       "      <td>0.539532</td>\n",
       "      <td>[0.4921953675730111, 0.4899669799339599, 0.494...</td>\n",
       "      <td>[0.07897856327914843, 0.08139581402184548, 0.0...</td>\n",
       "      <td>[0.0809298898123265, 0.08335374421962041, 0.08...</td>\n",
       "      <td>[0.4393258426966292, 0.43761343012704174, 0.44...</td>\n",
       "      <td>[0.5595306239267316, 0.5565493364108482, 0.562...</td>\n",
       "      <td>[0.5412831861747976, 0.5425834721605487, 0.543...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f1     kappa  matthews  precision    recall   roc_auc  stock  \\\n",
       "9061   0.497593  0.099606  0.101253   0.491552  0.513918  0.550135   9061   \n",
       "3459   0.346803  0.093323  0.123657   0.235997  0.659755  0.578305   3459   \n",
       "4549   0.444472  0.111446  0.126050   0.345721  0.628882  0.568979   4549   \n",
       "9761   0.425296  0.140375  0.145372   0.365136  0.511876  0.579031   9761   \n",
       "4851   0.293089  0.105413  0.146541   0.189271  0.654920  0.606391   4851   \n",
       "9062   0.519890  0.061360  0.062361   0.479484  0.568150  0.531206   9062   \n",
       "11869  0.425378  0.109039  0.122881   0.332377  0.606232  0.567714  11869   \n",
       "12255  0.420016  0.138216  0.146256   0.345570  0.537134  0.581062  12255   \n",
       "2748   0.261750  0.078826  0.091470   0.208937  0.454939  0.554845   2748   \n",
       "4320   0.455860  0.123911  0.135066   0.366351  0.604171  0.573556   4320   \n",
       "11583  0.496518  0.103416  0.113281   0.410968  0.633230  0.557927  11583   \n",
       "4799   0.419942  0.111573  0.129108   0.316442  0.626217  0.573225   4799   \n",
       "9268   0.441328  0.106374  0.119692   0.350044  0.609453  0.564564   9268   \n",
       "10470  0.415425  0.121182  0.142101   0.308560  0.638472  0.581989  10470   \n",
       "9058   0.491008  0.076422  0.078425   0.437605  0.559800  0.540008   9058   \n",
       "\n",
       "       test_f1_score  test_kappa  test_matthews  \\\n",
       "9061        0.514865    0.087674       0.089317   \n",
       "3459        0.355052    0.108968       0.131771   \n",
       "4549        0.369752   -0.010462      -0.012427   \n",
       "9761        0.418251    0.107302       0.110216   \n",
       "4851        0.281892    0.085375       0.131945   \n",
       "9062        0.524476    0.050556       0.052097   \n",
       "11869       0.412271    0.099398       0.104974   \n",
       "12255       0.415247    0.096768       0.108394   \n",
       "2748        0.216625   -0.005671      -0.008427   \n",
       "4320        0.444010    0.129812       0.135263   \n",
       "11583       0.435613   -0.021474      -0.024324   \n",
       "4799        0.410857    0.110791       0.121606   \n",
       "9268        0.459596    0.120074       0.131940   \n",
       "10470       0.420223    0.111498       0.126214   \n",
       "9058        0.497115    0.092606       0.094555   \n",
       "\n",
       "                             ...                          train_matthews  \\\n",
       "9061                         ...                                0.084010   \n",
       "3459                         ...                                0.130553   \n",
       "4549                         ...                               -0.023102   \n",
       "9761                         ...                                0.127401   \n",
       "4851                         ...                                0.134776   \n",
       "9062                         ...                                0.063964   \n",
       "11869                        ...                                0.118834   \n",
       "12255                        ...                                0.125885   \n",
       "2748                         ...                                0.021764   \n",
       "4320                         ...                                0.147290   \n",
       "11583                        ...                               -0.033182   \n",
       "4799                         ...                                0.110880   \n",
       "9268                         ...                                0.124912   \n",
       "10470                        ...                                0.129047   \n",
       "9058                         ...                                0.077495   \n",
       "\n",
       "       train_precision  train_recall  train_roc_auc  \\\n",
       "9061          0.473642      0.563770       0.542363   \n",
       "3459          0.247441      0.635929       0.582217   \n",
       "4549          0.282660      0.554722       0.487429   \n",
       "9761          0.367224      0.494805       0.568335   \n",
       "4851          0.192221      0.714385       0.594016   \n",
       "9062          0.477580      0.597335       0.531897   \n",
       "11869         0.324307      0.572923       0.566919   \n",
       "12255         0.333817      0.604538       0.570263   \n",
       "2748          0.151473      0.514503       0.515508   \n",
       "4320          0.385433      0.564751       0.579239   \n",
       "11583         0.347686      0.561292       0.482970   \n",
       "4799          0.323346      0.582380       0.562204   \n",
       "9268          0.364625      0.587245       0.567742   \n",
       "10470         0.304940      0.642238       0.574132   \n",
       "9058          0.437583      0.557695       0.539532   \n",
       "\n",
       "                                            train_val_f1  \\\n",
       "9061   [0.48513827862496767, 0.46519202062695075, 0.4...   \n",
       "3459   [0.36643219368558805, 0.37091264031234755, 0.3...   \n",
       "4549   [0.4154952598888526, 0.41458299725762215, 0.44...   \n",
       "9761   [0.4483916083916084, 0.4189549662639259, 0.407...   \n",
       "4851   [0.31987991994663106, 0.3283737024221453, 0.32...   \n",
       "9062   [0.5312393308296347, 0.5292244712303844, 0.528...   \n",
       "11869  [0.39735772357723576, 0.3945140535049103, 0.40...   \n",
       "12255  [0.427263479145473, 0.42742276766821835, 0.428...   \n",
       "2748   [0.1970746728252502, 0.20774487471526198, 0.19...   \n",
       "4320   [0.48148148148148157, 0.4751958224543081, 0.45...   \n",
       "11583  [0.4632989115266536, 0.5016509433962264, 0.502...   \n",
       "4799   [0.41729761211415256, 0.416260162601626, 0.421...   \n",
       "9268   [0.43129032258064515, 0.45442838746601805, 0.4...   \n",
       "10470  [0.4161394629551526, 0.40166882462954967, 0.39...   \n",
       "9058   [0.4921953675730111, 0.4899669799339599, 0.494...   \n",
       "\n",
       "                                         train_val_kappa  \\\n",
       "9061   [0.07541622814166549, 0.07436635023761451, 0.0...   \n",
       "3459   [0.11068791437404635, 0.11388203740888381, 0.1...   \n",
       "4549   [0.1133391131902024, 0.10787921816098733, 0.10...   \n",
       "9761   [0.10629670812162728, 0.1058349086570548, 0.11...   \n",
       "4851   [0.09450526395297976, 0.10938668717232536, 0.1...   \n",
       "9062   [0.06732105946098077, 0.06276835314999507, 0.0...   \n",
       "11869  [0.1144433911912599, 0.11096215581148583, 0.10...   \n",
       "12255  [0.0961386723705897, 0.09462290018094621, 0.11...   \n",
       "2748   [0.056794689296525425, 0.05508665549958858, 0....   \n",
       "4320   [0.1339327014120122, 0.1580016126696191, 0.163...   \n",
       "11583  [0.09957174022126758, 0.08704232152473856, 0.0...   \n",
       "4799   [0.08250192354959152, 0.09017513171986236, 0.1...   \n",
       "9268   [0.1239176031724506, 0.12317860195160124, 0.10...   \n",
       "10470  [0.09754143976995044, 0.09133215776089021, 0.0...   \n",
       "9058   [0.07897856327914843, 0.08139581402184548, 0.0...   \n",
       "\n",
       "                                      train_val_matthews  \\\n",
       "9061   [0.07549759566248633, 0.0743840975752264, 0.08...   \n",
       "3459   [0.1375948325984511, 0.14128969867782512, 0.13...   \n",
       "4549   [0.11717896366058196, 0.1121591275914303, 0.12...   \n",
       "9761   [0.11686657327253876, 0.11140406459736009, 0.1...   \n",
       "4851   [0.13215161824598573, 0.14791349497697015, 0.1...   \n",
       "9062   [0.06900973402586912, 0.06437256470834406, 0.0...   \n",
       "11869  [0.12202325950135805, 0.11857469519514513, 0.1...   \n",
       "12255  [0.10595648786121947, 0.10839509666510291, 0.1...   \n",
       "2748   [0.056835699352604664, 0.07861471243916973, 0....   \n",
       "4320   [0.14685468697513263, 0.16839180339384435, 0.1...   \n",
       "11583  [0.10194356282982467, 0.09854128216431536, 0.0...   \n",
       "4799   [0.09114513573979705, 0.09979146929501058, 0.1...   \n",
       "9268   [0.12580197480673536, 0.13333909594845167, 0.1...   \n",
       "10470  [0.11828182298290651, 0.11149021907733327, 0.1...   \n",
       "9058   [0.0809298898123265, 0.08335374421962041, 0.08...   \n",
       "\n",
       "                                     train_val_precision  \\\n",
       "9061   [0.47291509196271103, 0.47113798790544253, 0.4...   \n",
       "3459   [0.2574712643678161, 0.2611683848797251, 0.253...   \n",
       "4549   [0.35592271072528703, 0.3514770240700219, 0.33...   \n",
       "9761   [0.3568566340160285, 0.34829115575267416, 0.34...   \n",
       "4851   [0.20975503062117234, 0.21781042001377093, 0.2...   \n",
       "9062   [0.47837671654027464, 0.47616124411704525, 0.4...   \n",
       "11869  [0.3214579336804604, 0.3181321682140907, 0.320...   \n",
       "12255  [0.33738811108560934, 0.32664941785252266, 0.3...   \n",
       "2748   [0.19090231170768082, 0.12998859749144812, 0.1...   \n",
       "4320   [0.3865546218487395, 0.3909307875894988, 0.384...   \n",
       "11583  [0.41078940856223706, 0.39943661971830985, 0.4...   \n",
       "4799   [0.3285943590919514, 0.32653061224489793, 0.32...   \n",
       "9268   [0.38787351319988395, 0.3669979200369771, 0.34...   \n",
       "10470  [0.3046521202140799, 0.29156223893065997, 0.28...   \n",
       "9058   [0.4393258426966292, 0.43761343012704174, 0.44...   \n",
       "\n",
       "                                        train_val_recall  \\\n",
       "9061   [0.49801008224993365, 0.45939426427231306, 0.4...   \n",
       "3459   [0.6352807714123653, 0.6397306397306397, 0.618...   \n",
       "4549   [0.49901845308205733, 0.5053086905230043, 0.66...   \n",
       "9761   [0.6030850263355907, 0.5255905511811023, 0.492...   \n",
       "4851   [0.6734550561797753, 0.6669009135628953, 0.657...   \n",
       "9062   [0.5972364380757421, 0.5955976452521116, 0.597...   \n",
       "11869  [0.5201773835920177, 0.5191622103386809, 0.557...   \n",
       "12255  [0.5824088748019017, 0.6181150550795593, 0.608...   \n",
       "2748   [0.20365950676213207, 0.5170068027210885, 0.47...   \n",
       "4320   [0.6382070437566703, 0.6057692307692307, 0.549...   \n",
       "11583  [0.5312, 0.6741679873217116, 0.67233238904627,...   \n",
       "4799   [0.5715995213402473, 0.5739910313901345, 0.600...   \n",
       "9268   [0.48565201598256447, 0.5965439519158527, 0.67...   \n",
       "10470  [0.656319290465632, 0.6453999075358299, 0.6702...   \n",
       "9058   [0.5595306239267316, 0.5565493364108482, 0.562...   \n",
       "\n",
       "                                       train_val_roc_auc  \n",
       "9061   [0.5379477368473236, 0.5370659747472899, 0.542...  \n",
       "3459   [0.5856668148931979, 0.5876170122173291, 0.586...  \n",
       "4549   [0.5633648432454638, 0.5608879266267561, 0.570...  \n",
       "9761   [0.5634511995037109, 0.5608550977409149, 0.565...  \n",
       "4851   [0.5892956694403876, 0.6000897336918831, 0.608...  \n",
       "9062   [0.5344496493887118, 0.5321284199693517, 0.532...  \n",
       "11869  [0.5687440240989454, 0.5669410804817923, 0.566...  \n",
       "12255  [0.5584194027291238, 0.5601732431916764, 0.571...  \n",
       "2748   [0.5291864753949922, 0.5639349964134577, 0.532...  \n",
       "4320   [0.5784034880602763, 0.5909596859708968, 0.591...  \n",
       "11583  [0.5530107142857144, 0.5500103850432616, 0.548...  \n",
       "4799   [0.5503542798081101, 0.5554904136542509, 0.563...  \n",
       "9268   [0.5661682718894738, 0.5723936978777681, 0.567...  \n",
       "10470  [0.5671086405960308, 0.5642421665079332, 0.573...  \n",
       "9058   [0.5412831861747976, 0.5425834721605487, 0.543...  \n",
       "\n",
       "[15 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_scores(df, column):\n",
    "    scores = []\n",
    "    for i, row in df.iterrows():\n",
    "        scores.append(np.mean(row[column]))\n",
    "    return scores\n",
    "scores_columns = ['f1', 'kappa', 'matthews', 'precision', 'recall', 'roc_auc', 'train_f1', 'train_kappa',\n",
    "       'train_matthews', 'train_precision', 'train_recall', 'train_roc_auc']\n",
    "\n",
    "for col in scores_columns:\n",
    "    df_scores[col] = convert_scores(df_scores, col)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pivot</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>-0.000036</td>\n",
       "      <td>9061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.046621</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.171668</td>\n",
       "      <td>9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>-0.050287</td>\n",
       "      <td>4851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>-0.090466</td>\n",
       "      <td>9062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.033717</td>\n",
       "      <td>11869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>-0.000888</td>\n",
       "      <td>12255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>-0.000039</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.098337</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.000635</td>\n",
       "      <td>11583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.031788</td>\n",
       "      <td>4799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>-0.013778</td>\n",
       "      <td>9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.009151</td>\n",
       "      <td>10470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.012648</td>\n",
       "      <td>9058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pivot  stock\n",
       "9061  -0.000036   9061\n",
       "3459   0.046621   3459\n",
       "4549  -0.000026   4549\n",
       "9761   0.171668   9761\n",
       "4851  -0.050287   4851\n",
       "9062  -0.090466   9062\n",
       "11869  0.033717  11869\n",
       "12255 -0.000888  12255\n",
       "2748  -0.000039   2748\n",
       "4320   0.098337   4320\n",
       "11583  0.000635  11583\n",
       "4799   0.031788   4799\n",
       "9268  -0.013778   9268\n",
       "10470  0.009151  10470\n",
       "9058   0.012648   9058"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivots = []\n",
    "print('Pivot values')\n",
    "for i in df_scores.index:\n",
    "    stock = i\n",
    "    df = d_stocks[stock]\n",
    "    \n",
    "    pivot = np.mean([np.min(df[df['pred'] == 1]['queue_imbalance']), \n",
    "                    np.max(df[df['pred'] == 0]['queue_imbalance'])])\n",
    "    pivots.append(pivot)\n",
    "df_scores['pivot'] = pivots\n",
    "df_scores[['pivot', 'stock']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_scores[['pivot', 'stock']]\n",
    "df_pivot['stock'] = df_pivot['stock'].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    15 non-null int64\n",
      "pivot         15 non-null float64\n",
      "stock         15 non-null int64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 440.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df_log = pd.read_csv('que_log_pivot.csv')\n",
    "df_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = pd.merge(df_pivot, df_log[['pivot', 'stock']], \n",
    "                    on='stock', suffixes=['', '_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pivot</th>\n",
       "      <th>pivot_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.023023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>0.046621</td>\n",
       "      <td>0.096860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.032053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>0.171668</td>\n",
       "      <td>0.043341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>-0.050287</td>\n",
       "      <td>0.089948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>-0.090466</td>\n",
       "      <td>0.012105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.037273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12255</th>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.046640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.038263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>0.098337</td>\n",
       "      <td>0.053965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.046703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0.031788</td>\n",
       "      <td>0.049480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>-0.013778</td>\n",
       "      <td>0.018577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.085225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>0.012648</td>\n",
       "      <td>0.031014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pivot  pivot_log\n",
       "stock                     \n",
       "9061  -0.000036   0.023023\n",
       "3459   0.046621   0.096860\n",
       "4549  -0.000026   0.032053\n",
       "9761   0.171668   0.043341\n",
       "4851  -0.050287   0.089948\n",
       "9062  -0.090466   0.012105\n",
       "11869  0.033717   0.037273\n",
       "12255 -0.000888   0.046640\n",
       "2748  -0.000039   0.038263\n",
       "4320   0.098337   0.053965\n",
       "11583  0.000635   0.046703\n",
       "4799   0.031788   0.049480\n",
       "9268  -0.013778   0.018577\n",
       "10470  0.009151   0.085225\n",
       "9058   0.012648   0.031014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.index = df_pivot['stock']\n",
    "df_pivot.drop(columns=['stock'], inplace=True)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pivot.plot(kind='bar')\n",
    "plt.legend(['Pivot for QUE+SVM', 'Pivot for QUE+LOG'])\n",
    "plt.title('Decision Boundary Pivot values comparision')\n",
    "plt.ylabel('Pivot value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('que_svm_log_pivot_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['stock'] = df_pivot.index\n",
    "df_pivot[['stock', 'pivot']].to_csv('que_svm_sig_pivot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
